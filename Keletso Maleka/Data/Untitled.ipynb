{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['doc'] = [nlp(text) for text in train.message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['num_tokens'] = [len(token) for token in train['doc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['countDict'] = train['doc'].apply(lambda x: [Counter(token.pos_ for token in x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Adj'] = train['countDict'].apply(lambda x: (x[0]['ADJ']))/train['num_tokens']*100\n",
    "train['Noun'] = train['countDict'].apply(lambda x: (x[0]['NOUN']))/train['num_tokens']*100\n",
    "train['Punct'] = train['countDict'].apply(lambda x: (x[0]['PUNCT']))/train['num_tokens']*100\n",
    "train['Verb'] = train['countDict'].apply(lambda x: (x[0]['VERB']))/train['num_tokens']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "train['Polarity'] = train['message'].apply(lambda x: sid.polarity_scores(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>doc</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>countDict</th>\n",
       "      <th>Adj</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Punct</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>(PolySciMajor, EPA, chief, does, n't, think, c...</td>\n",
       "      <td>24</td>\n",
       "      <td>[{'PROPN': 2, 'NOUN': 6, 'VERB': 4, 'ADV': 1, ...</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.905, 'pos': 0.095, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>(It, 's, not, like, we, lack, evidence, of, an...</td>\n",
       "      <td>11</td>\n",
       "      <td>[{'PRON': 2, 'VERB': 2, 'ADV': 1, 'ADP': 2, 'N...</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>{'neg': 0.167, 'neu': 0.552, 'pos': 0.281, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>(RT, @RawStory, :, Researchers, say, we, have,...</td>\n",
       "      <td>22</td>\n",
       "      <td>[{'PROPN': 3, 'PUNCT': 2, 'NOUN': 4, 'VERB': 4...</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>(#, TodayinMaker, #, WIRED, :, 2016, was, a, p...</td>\n",
       "      <td>17</td>\n",
       "      <td>[{'SYM': 1, 'PROPN': 3, 'PUNCT': 1, 'NUM': 1, ...</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>23.529412</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>{'neg': 0.245, 'neu': 0.755, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>(RT, @SoyNovioDeTodas, :, It, 's, 2016, ,, and...</td>\n",
       "      <td>25</td>\n",
       "      <td>[{'PROPN': 1, 'VERB': 5, 'PUNCT': 5, 'PRON': 1...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>{'neg': 0.299, 'neu': 0.701, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                                 doc  num_tokens  \\\n",
       "0  (PolySciMajor, EPA, chief, does, n't, think, c...          24   \n",
       "1  (It, 's, not, like, we, lack, evidence, of, an...          11   \n",
       "2  (RT, @RawStory, :, Researchers, say, we, have,...          22   \n",
       "3  (#, TodayinMaker, #, WIRED, :, 2016, was, a, p...          17   \n",
       "4  (RT, @SoyNovioDeTodas, :, It, 's, 2016, ,, and...          25   \n",
       "\n",
       "                                           countDict        Adj       Noun  \\\n",
       "0  [{'PROPN': 2, 'NOUN': 6, 'VERB': 4, 'ADV': 1, ...  12.500000  25.000000   \n",
       "1  [{'PRON': 2, 'VERB': 2, 'ADV': 1, 'ADP': 2, 'N...  18.181818  18.181818   \n",
       "2  [{'PROPN': 3, 'PUNCT': 2, 'NOUN': 4, 'VERB': 4...   4.545455  18.181818   \n",
       "3  [{'SYM': 1, 'PROPN': 3, 'PUNCT': 1, 'NUM': 1, ...   5.882353  23.529412   \n",
       "4  [{'PROPN': 1, 'VERB': 5, 'PUNCT': 5, 'PRON': 1...   4.000000  24.000000   \n",
       "\n",
       "       Punct       Verb                                           Polarity  \n",
       "0  16.666667  16.666667  {'neg': 0.0, 'neu': 0.905, 'pos': 0.095, 'comp...  \n",
       "1   0.000000  18.181818  {'neg': 0.167, 'neu': 0.552, 'pos': 0.281, 'co...  \n",
       "2   9.090909  18.181818  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3   5.882353  11.764706  {'neg': 0.245, 'neu': 0.755, 'pos': 0.0, 'comp...  \n",
       "4  20.000000  20.000000  {'neg': 0.299, 'neu': 0.701, 'pos': 0.0, 'comp...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['compound']  = train['Polarity'].apply(lambda score_dict: score_dict['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>doc</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>countDict</th>\n",
       "      <th>Adj</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Punct</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>(PolySciMajor, EPA, chief, does, n't, think, c...</td>\n",
       "      <td>24</td>\n",
       "      <td>[{'PROPN': 2, 'NOUN': 6, 'VERB': 4, 'ADV': 1, ...</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.905, 'pos': 0.095, 'comp...</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>(It, 's, not, like, we, lack, evidence, of, an...</td>\n",
       "      <td>11</td>\n",
       "      <td>[{'PRON': 2, 'VERB': 2, 'ADV': 1, 'ADP': 2, 'N...</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>{'neg': 0.167, 'neu': 0.552, 'pos': 0.281, 'co...</td>\n",
       "      <td>0.1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>(RT, @RawStory, :, Researchers, say, we, have,...</td>\n",
       "      <td>22</td>\n",
       "      <td>[{'PROPN': 3, 'PUNCT': 2, 'NOUN': 4, 'VERB': 4...</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>(#, TodayinMaker, #, WIRED, :, 2016, was, a, p...</td>\n",
       "      <td>17</td>\n",
       "      <td>[{'SYM': 1, 'PROPN': 3, 'PUNCT': 1, 'NUM': 1, ...</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>23.529412</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>{'neg': 0.245, 'neu': 0.755, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>(RT, @SoyNovioDeTodas, :, It, 's, 2016, ,, and...</td>\n",
       "      <td>25</td>\n",
       "      <td>[{'PROPN': 1, 'VERB': 5, 'PUNCT': 5, 'PRON': 1...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>{'neg': 0.299, 'neu': 0.701, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.7506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "\n",
       "                                                 doc  num_tokens  \\\n",
       "0  (PolySciMajor, EPA, chief, does, n't, think, c...          24   \n",
       "1  (It, 's, not, like, we, lack, evidence, of, an...          11   \n",
       "2  (RT, @RawStory, :, Researchers, say, we, have,...          22   \n",
       "3  (#, TodayinMaker, #, WIRED, :, 2016, was, a, p...          17   \n",
       "4  (RT, @SoyNovioDeTodas, :, It, 's, 2016, ,, and...          25   \n",
       "\n",
       "                                           countDict        Adj       Noun  \\\n",
       "0  [{'PROPN': 2, 'NOUN': 6, 'VERB': 4, 'ADV': 1, ...  12.500000  25.000000   \n",
       "1  [{'PRON': 2, 'VERB': 2, 'ADV': 1, 'ADP': 2, 'N...  18.181818  18.181818   \n",
       "2  [{'PROPN': 3, 'PUNCT': 2, 'NOUN': 4, 'VERB': 4...   4.545455  18.181818   \n",
       "3  [{'SYM': 1, 'PROPN': 3, 'PUNCT': 1, 'NUM': 1, ...   5.882353  23.529412   \n",
       "4  [{'PROPN': 1, 'VERB': 5, 'PUNCT': 5, 'PRON': 1...   4.000000  24.000000   \n",
       "\n",
       "       Punct       Verb                                           Polarity  \\\n",
       "0  16.666667  16.666667  {'neg': 0.0, 'neu': 0.905, 'pos': 0.095, 'comp...   \n",
       "1   0.000000  18.181818  {'neg': 0.167, 'neu': 0.552, 'pos': 0.281, 'co...   \n",
       "2   9.090909  18.181818  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "3   5.882353  11.764706  {'neg': 0.245, 'neu': 0.755, 'pos': 0.0, 'comp...   \n",
       "4  20.000000  20.000000  {'neg': 0.299, 'neu': 0.701, 'pos': 0.0, 'comp...   \n",
       "\n",
       "   compound  \n",
       "0    0.2244  \n",
       "1    0.1159  \n",
       "2    0.0000  \n",
       "3   -0.5994  \n",
       "4   -0.7506  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train[['num_tokens','Adj','Noun','Punct','Verb','compound','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train[['Verb','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verb</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.181818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.181818</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.764706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Verb  sentiment\n",
       "0  16.666667          1\n",
       "1  18.181818          1\n",
       "2  18.181818          2\n",
       "3  11.764706          1\n",
       "4  20.000000          1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('nearmiss', NearMiss(version=2)), ('linearsvc', LinearSVC())])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(NearMiss(version=2),\n",
    "                         LinearSVC())\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 261    0   86   54]\n",
      " [ 417    0  154   95]\n",
      " [1605    0  630  363]\n",
      " [ 841    0  114  126]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Create a prediction set:\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.08      0.65      0.15       401\n",
      "           0       0.00      0.00      0.00       666\n",
      "           1       0.64      0.24      0.35      2598\n",
      "           2       0.20      0.12      0.15      1081\n",
      "\n",
      "    accuracy                           0.21      4746\n",
      "   macro avg       0.23      0.25      0.16      4746\n",
      "weighted avg       0.40      0.21      0.24      4746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         -1       0.08      0.65      0.34      0.15      0.47      0.23       401\n",
      "          0       0.00      0.00      1.00      0.00      0.00      0.00       666\n",
      "          1       0.64      0.24      0.84      0.35      0.45      0.19      2598\n",
      "          2       0.20      0.12      0.86      0.15      0.32      0.09      1081\n",
      "\n",
      "avg / total       0.40      0.21      0.82      0.24      0.36      0.14      4746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
